
# ğŸ“… Day 1: Beginner Walkthrough â€“ **Introduction to Data Cleaning and Loading Data**

---

## ğŸ§  Why Data Cleaning and Loading Matter

Before we can visualize, analyze, or model data, we need to **load it** and **clean it**. This step is foundational â€” like sharpening your tools before starting a project.

### ğŸ’¡ Real-World Analogy:

Imagine a restaurant receiving ingredients. If some vegetables are spoiled or mislabeled, cooking a delicious meal becomes impossible. Similarly, messy data leads to inaccurate insights â€” also known as **"garbage in, garbage out."**

---

## ğŸ§¹ Common Data Quality Issues Youâ€™ll Encounter

| ğŸ”§ Problem              | ğŸ’¥ Example                                       |
| ----------------------- | ------------------------------------------------ |
| Missing Values          | A customer record with no email or age           |
| Duplicates              | A product listed multiple times in a catalog     |
| Wrong Data Types        | A price column stored as text instead of numbers |
| Inconsistent Formatting | "USA" vs "U.S.A." vs "United States"             |
| Outliers or Typos       | Age of 999 or salary of -\$1000                  |

---

## ğŸ“¦ Step 1: Load Data into Pandas

First, import the **Pandas** library â€” your go-to tool for working with structured data in Python.

```python
import pandas as pd
```

---

### ğŸ“ 1. Loading a CSV File

CSV (Comma Separated Values) is the most common format for tabular data.

```python
# Load CSV data
df = pd.read_csv('employee_data.csv')

# View the first few rows
print(df.head())

# View basic information
print(df.info())
```

ğŸ‘€ `df.head()` gives you a sneak peek.
ğŸ§¾ `df.info()` shows row count, column types, and null values.

---

### ğŸ“Š 2. Loading an Excel File

Excel files may contain multiple sheets. You'll need `openpyxl`:

```bash
pip install openpyxl
```

```python
# Load the first sheet
df_excel = pd.read_excel('employee_data.xlsx')
print(df_excel.head())

# Load a specific sheet by name
df_sheet = pd.read_excel('employee_data.xlsx', sheet_name='Sheet2')
```

---

### ğŸ§¾ 3. Loading a JSON File

Useful for hierarchical or nested data (e.g., API responses):

```python
df_json = pd.read_json('employee_data.json')
print(df_json.head())
print(df_json.info())
```

---

## ğŸ§ª Hands-On Activity â€“ Load and Explore Employee Data

### ğŸ“¥ Download Sample Data

* CSV: [Employee Heights and Weights](https://people.sc.fsu.edu/~jburkardt/data/csv/hw_200.csv)
* Save as `employee_data.csv`.

---

### ğŸ” Step-by-Step: Load and Clean the CSV File

```python
import pandas as pd

# Load the dataset
df = pd.read_csv('employee_data.csv')

# Display first 5 rows
print(df.head())

# Show data types and nulls
print(df.info())

# Check for missing values
print(df.isnull().sum())
```

---

### ğŸ“Œ Check for Duplicates

Sometimes data is repeated unintentionally. Letâ€™s find out:

```python
duplicate_count = df.duplicated().sum()
print(f"Duplicate Rows: {duplicate_count}")
```

To remove them:

```python
df = df.drop_duplicates()
```

---

## ğŸ“‚ Optional: Load JSON Data

Create a file named `employee_data.json` and paste:

```json
[
  {"Name": "Alice", "Age": 25, "Department": "HR"},
  {"Name": "Bob", "Age": 30, "Department": "IT"},
  {"Name": "Charlie", "Age": 35, "Department": "Finance"}
]
```

Then load it with Pandas:

```python
df_json = pd.read_json('employee_data.json')
print(df_json.info())
print(df_json.head())
```

---

## ğŸ§© Pro Tips and Notes

* Always use `df.info()` right after loading any dataset.
* For large datasets, use `nrows=100` to load a sample.
* Clean column names:

```python
df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")
```

---

## ğŸ§  Learning Outcomes

By the end of Day 1, you will be able to:
âœ… Load datasets from CSV, Excel, and JSON
âœ… Inspect data using `.head()`, `.info()`, and `.describe()`
âœ… Detect missing values and duplicates
âœ… Understand common formatting pitfalls

---

## ğŸ” Reflection & Real-World Scenario

> Imagine youâ€™re working for a human resources team analyzing employee salary trends. If ages are recorded as text and departments have inconsistent labels (e.g., â€œITâ€ vs â€œitâ€), your summaries and dashboards may be completely wrong.

Cleaning ensures you're working with **trustworthy, structured, and consistent data**.

---

## ğŸ’ª Challenge Tasks

1. âœ… Download and load a different dataset (e.g., from [Kaggle](https://www.kaggle.com/datasets) or [data.gov](https://catalog.data.gov/))
2. âœ… Use `.isnull().sum()` and `.duplicated().sum()` on the dataset
3. âœ… Clean column names using string functions
4. âœ… Save the cleaned dataset to a new CSV file:

```python
df.to_csv('cleaned_data.csv', index=False)
```

