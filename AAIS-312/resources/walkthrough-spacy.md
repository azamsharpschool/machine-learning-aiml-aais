# **Walkthrough: Basic Functionalities of spaCy in Python**

## **Introduction to spaCy**
**spaCy** is an advanced, high-performance **Natural Language Processing (NLP)** library designed for **tokenization, Named Entity Recognition (NER), Part-of-Speech (POS) tagging, dependency parsing, lemmatization**, and more.

### **Why Use spaCy?**
âœ… **Fast and Efficient** â€“ Optimized for real-world NLP tasks.  
âœ… **Pre-trained Models** â€“ Provides ready-to-use models for multiple languages.  
âœ… **Production-Ready** â€“ Widely used in enterprise applications.  

---

## **1. Installation**
Before using spaCy, install the package and download a language model:

```bash
pip install spacy
python -m spacy download en_core_web_sm
```
- `en_core_web_sm` is a **small English language model** with basic NLP features.
- Other models include:
  - `en_core_web_md` (Medium model, includes word vectors)
  - `en_core_web_lg` (Large model with better accuracy)

---

## **2. Loading a Language Model**
```python
import spacy

# Load the English model
nlp = spacy.load("en_core_web_sm")

# Sample text
text = "Apple Inc. is planning to build a new office in San Francisco."
doc = nlp(text)
```
- `nlp` **processes** the text and returns a **Doc** object (`doc`).
- `doc` contains **tokens, POS tags, named entities, dependency structure, and more**.

---

## **3. Tokenization**
Tokenization is the process of **splitting text** into meaningful units (**tokens**).
```python
for token in doc:
    print(token.text)
```
**Output:**
```
Apple
Inc.
is
planning
to
build
a
new
office
in
San
Francisco
.
```
ğŸ”¹ **spaCy's tokenization preserves punctuation and special characters**.

---

## **4. Stopword Removal**
**Stopwords** are common words like `"the"`, `"is"`, `"a"` that donâ€™t add much meaning.
```python
filtered_tokens = [token.text for token in doc if not token.is_stop]
print(filtered_tokens)
```
**Output:**
```
['Apple', 'Inc.', 'planning', 'build', 'new', 'office', 'San', 'Francisco', '.']
```
ğŸ”¹ **Only meaningful words remain**.

---

## **5. Lemmatization**
Lemmatization converts words into their **root (dictionary) form**.
```python
for token in doc:
    print(f"{token.text} â†’ {token.lemma_}")
```
**Output:**
```
Apple â†’ Apple
Inc. â†’ Inc.
is â†’ be
planning â†’ plan
to â†’ to
build â†’ build
a â†’ a
new â†’ new
office â†’ office
in â†’ in
San â†’ San
Francisco â†’ Francisco
. â†’ .
```
ğŸ”¹ `"planning"` becomes `"plan"`, `"is"` becomes `"be"`.

---

## **6. Part-of-Speech (POS) Tagging**
Each token is assigned a **grammatical category** (e.g., noun, verb, adjective).
```python
for token in doc:
    print(f"{token.text}: {token.pos_}")
```
**Output:**
```
Apple: PROPN
Inc.: PROPN
is: AUX
planning: VERB
to: PART
build: VERB
a: DET
new: ADJ
office: NOUN
in: ADP
San: PROPN
Francisco: PROPN
.: PUNCT
```
ğŸ”¹ `"planning"` is labeled as a `VERB`, `"Apple"` as a `PROPN` (Proper Noun).

---

## **7. Named Entity Recognition (NER)**
spaCy identifies **real-world entities** like companies, locations, and dates.
```python
for ent in doc.ents:
    print(f"{ent.text}: {ent.label_}")
```
**Output:**
```
Apple Inc.: ORG
San Francisco: GPE
```
ğŸ”¹ `"Apple Inc."` is labeled as an `ORG` (Organization), `"San Francisco"` as `GPE` (Geopolitical Entity).

---

## **8. Dependency Parsing**
Dependency parsing shows **relationships between words** in a sentence.
```python
for token in doc:
    print(f"{token.text} â†’ {token.dep_} â†’ {token.head.text}")
```
**Output:**
```
Apple â†’ compound â†’ Inc.
Inc. â†’ nsubj â†’ planning
is â†’ aux â†’ planning
planning â†’ ROOT â†’ planning
to â†’ aux â†’ build
build â†’ xcomp â†’ planning
a â†’ det â†’ office
new â†’ amod â†’ office
office â†’ dobj â†’ build
in â†’ prep â†’ build
San â†’ compound â†’ Francisco
Francisco â†’ pobj â†’ in
. â†’ punct â†’ planning
```
ğŸ”¹ `"planning"` is the **ROOT** (main verb), `"Apple"` is the **subject**.

---

## **9. Visualizing NLP Features**
### **Dependency Tree Visualization**
```python
from spacy import displacy
displacy.render(doc, style="dep", jupyter=True)
```
**Output:**  
â¡ï¸ **Dependency tree graph** showing how words are connected.

### **NER Visualization**
```python
displacy.render(doc, style="ent", jupyter=True)
```
**Output:**  
â¡ï¸ Entities are **highlighted** in different colors.

---

## **10. Custom Stopwords**
You can **add or remove** stopwords.
```python
# Add "planning" as a stopword
nlp.Defaults.stop_words.add("planning")

# Remove "the" from stopwords
nlp.Defaults.stop_words.remove("the")
```
ğŸ”¹ Useful for **custom NLP pipelines**.

---

## **11. Custom Tokenizer**
You can create a **custom tokenizer** for domain-specific NLP.
```python
from spacy.tokenizer import Tokenizer

# Create a custom tokenizer
custom_tokenizer = Tokenizer(nlp.vocab, rules={"AI": [{"ORTH": "AI"}]})
nlp.tokenizer = custom_tokenizer

# Test custom tokenizer
doc = nlp("AI is changing the world.")
print([token.text for token in doc])
```
**Output:**
```
['AI', 'is', 'changing', 'the', 'world', '.']
```
ğŸ”¹ `"AI"` is treated as a **single token**.

---

## **12. Text Similarity**
spaCy can measure **semantic similarity** between texts.
```python
doc1 = nlp("I love cats.")
doc2 = nlp("I adore felines.")

# Compute similarity
print(doc1.similarity(doc2))
```
**Output:**  
```
0.85  # (High similarity)
```
ğŸ”¹ `"cats"` and `"felines"` are similar due to **word embeddings**.

---

## **13. Sentiment Analysis (via Pre-trained Models)**
While spaCy does not include built-in sentiment analysis, it can be done using external libraries like **TextBlob** or **VADER**:
```python
from textblob import TextBlob

text = "I love spaCy! It's the best NLP tool."
sentiment = TextBlob(text).sentiment
print(sentiment)
```
**Output:**
```
Sentiment(polarity=0.9, subjectivity=0.75)
```
ğŸ”¹ **Polarity** = 0.9 (Very positive sentiment).  
ğŸ”¹ **Subjectivity** = 0.75 (Highly opinionated).

---

## **Summary**
âœ… **Tokenization** â€“ Splitting text into words/sentences.  
âœ… **Stopword Removal** â€“ Removing unimportant words.  
âœ… **Lemmatization** â€“ Converting words to base forms.  
âœ… **POS Tagging** â€“ Identifying word types (noun, verb, etc.).  
âœ… **Named Entity Recognition (NER)** â€“ Identifying real-world entities.  
âœ… **Dependency Parsing** â€“ Understanding grammatical structure.  
âœ… **Visualization** â€“ Displaying NLP features using **displacy**.  
âœ… **Customization** â€“ Creating **custom stopwords, tokenizers, and rules**.  
âœ… **Similarity & Sentiment Analysis** â€“ Measuring **semantic similarity** and **emotion**.  

---

## **Whatâ€™s Next?**
ğŸ”¹ **Train a Custom NLP Model** â€“ Fine-tune spaCy for **your dataset**.  
ğŸ”¹ **Use spaCy for Chatbots** â€“ Build an intelligent **AI assistant**.  
ğŸ”¹ **Integrate spaCy with Machine Learning** â€“ Combine **NLP & ML models**.  

ğŸš€ **Now youâ€™re ready to use spaCy for real-world NLP tasks!** ğŸš€